lwd = 2)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=128, input_shape = c(7, 6), activation="relu") %>%
layer_lstm(units=64, activation = "relu") %>%
layer_lstm(units=32) %>%
layer_dense(units=1, activation = "linear")
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=128, input_shape = c(7, 6), activation="relu") %>%
layer_lstm(units=64, activation = "relu") %>%
layer_lstm(units=32) %>%
layer_dense(units=1, activation = "linear")
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 75,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 2)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 150,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 2)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 250,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 2)
lines(yhat, col = "red", lwd = 2)
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 1)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 250,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 1)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 150,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 1)
lines(yhat, col = "red", lwd = 2)
# LSTM
model = keras_model_sequential() %>%
layer_lstm(units=24, input_shape = c(7, 6), activation="tanh") %>%
layer_dense(units=1, activation = "linear")
model %>% compile(loss = 'mse',
optimizer = 'adam',
metrics = list("mean_absolute_error")
)
model %>% summary()
history <- model %>% fit(X[[1]][train,, ], y[[1]][train],
batch_size = 12, epochs = 75,
validation_data = list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "LSTM Forecasting for Covid-19 Cases",
lwd = 1)
lines(yhat, col = "red", lwd = 2)
library(tsibble)
library(fpp3)
load("~/Dropbox/ToolShed_draft/toronto2.rds")
toronto2 <- data
df <- toronto2 %>%
mutate(dcases = difference(cases),
dmob = difference(mob),
ddelay = difference(delay),
dmale = difference(male),
dtemp = difference(temp),
dhum = difference(hum))
dft <- df[ ,-c(2:5,7,8)] #removing levels
dft <- dft[-1, c(3:7,2)] # reordering the columns
sdtf <- scale(dft) #
head(sdtf)
tensorin <- function(l, x){
maxl = l+1
xm <- embed(x, maxl)
xm <- xm[, -c(2:3)]
n <- nrow(xm)
f1 <- data.matrix(xm[, -1])
y <- xm[, 1]
f2 <- array(f1, c(n, ncol(x), l))
f3 <- f2[,, l:1]
f4 <- aperm(f3, c(1, 3, 2))
list(f4, y)
}
trnt <- tensorin(7, sdtf)
X <- trnt[1]
y <- trnt[2]
X[[1]][1,,]
y[[1]][1]
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
dim(X[[1]])
train <- 1:208
test <- 208:dim(X[[1]])[1]
tensorflow::set_random_seed(432)
history <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- predict(model, X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "RNN Forecasting for Covid-19 Cases")
lines(yhat, col = "red", lwd = 2)
plot(y[[1]][test], type ="l", col = "blue",
ylab = "Actual (Blue) vs. Prediction (Red)",
xlab = "Last 50 Days",
main = "RNN Forecasting for Covid-19 Cases")
lines(yhat, col = "red", lwd = 2)
library(tsibble)
library(fpp3)
load("~/Dropbox/ToolShed_draft/toronto2.rds")
toronto2 <- data
df <- toronto2 %>%
mutate(dcases = difference(cases),
dmob = difference(mob),
ddelay = difference(delay),
dmale = difference(male),
dtemp = difference(temp),
dhum = difference(hum))
dft <- df[ ,-c(2:5,7,8)] #removing levels
dft <- dft[-1, c(3:7,2)] # reordering the columns
sdtf <- scale(dft) #
head(sdtf)
tensorin <- function(l, x){
maxl = l+1
xm <- embed(x, maxl)
xm <- xm[, -c(2:3)]
n <- nrow(xm)
f1 <- data.matrix(xm[, -1])
y <- xm[, 1]
f2 <- array(f1, c(n, ncol(x), l))
f3 <- f2[,, l:1]
f4 <- aperm(f3, c(1, 3, 2))
list(f4, y)
}
trnt <- tensorin(7, sdtf)
X <- trnt[1]
y <- trnt[2]
X[[1]][1,,]
y[[1]][1]
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
dim(X[[1]])
train <- 1:208
test <- 208:dim(X[[1]])[1]
tensorflow::set_random_seed(432)
history <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- model %>% predict(X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
library(tsibble)
library(fpp3)
load("~/Dropbox/ToolShed_draft/toronto2.rds")
toronto2 <- data
df <- toronto2 %>%
mutate(dcases = difference(cases),
dmob = difference(mob),
ddelay = difference(delay),
dmale = difference(male),
dtemp = difference(temp),
dhum = difference(hum))
dft <- df[ ,-c(2:5,7,8)] #removing levels
dft <- dft[-1, c(3:7,2)] # reordering the columns
sdtf <- scale(dft) #
head(sdtf)
tensorin <- function(l, x){
maxl = l+1
xm <- embed(x, maxl)
xm <- xm[, -c(2:3)]
n <- nrow(xm)
f1 <- data.matrix(xm[, -1])
y <- xm[, 1]
f2 <- array(f1, c(n, ncol(x), l))
f3 <- f2[,, l:1]
f4 <- aperm(f3, c(1, 3, 2))
list(f4, y)
}
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
dim(X[[1]])
trnt <- tensorin(7, sdtf)
X <- trnt[1]
y <- trnt[2]
X[[1]][1,,]
y[[1]][1]
dim(X[[1]])
train <- 1:208
test <- 208:dim(X[[1]])[1]
tensorflow::set_random_seed(432)
history <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- model %>% keras::predict(X[[1]][test,, ])
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- model %>% predict(X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
library(tsibble)
library(fpp3)
load("~/Dropbox/ToolShed_draft/toronto2.rds")
toronto2 <- data
df <- toronto2 %>%
mutate(dcases = difference(cases),
dmob = difference(mob),
ddelay = difference(delay),
dmale = difference(male),
dtemp = difference(temp),
dhum = difference(hum))
dft <- df[ ,-c(2:5,7,8)] #removing levels
dft <- dft[-1, c(3:7,2)] # reordering the columns
sdtf <- scale(dft) #
head(sdtf)
tensorin <- function(l, x){
maxl = l+1
xm <- embed(x, maxl)
xm <- xm[, -c(2:3)]
n <- nrow(xm)
f1 <- data.matrix(xm[, -1])
y <- xm[, 1]
f2 <- array(f1, c(n, ncol(x), l))
f3 <- f2[,, l:1]
f4 <- aperm(f3, c(1, 3, 2))
list(f4, y)
}
trnt <- tensorin(7, sdtf)
X <- trnt[1]
y <- trnt[2]
X[[1]][1,,]
y[[1]][1]
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
model
history <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
dim(X[[1]])
dim(X[[1]])
train <- 1:208
test <- 208:dim(X[[1]])[1]
history <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
plot(history)
rnn <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
rnn %>% plot()
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
library(tsibble)
library(fpp3)
load("~/Dropbox/ToolShed_draft/toronto2.rds")
toronto2 <- data
df <- toronto2 %>%
mutate(dcases = difference(cases),
dmob = difference(mob),
ddelay = difference(delay),
dmale = difference(male),
dtemp = difference(temp),
dhum = difference(hum))
dft <- df[ ,-c(2:5,7,8)] #removing levels
dft <- dft[-1, c(3:7,2)] # reordering the columns
sdtf <- scale(dft) #
head(sdtf)
tensorin <- function(l, x){
maxl = l+1
xm <- embed(x, maxl)
xm <- xm[, -c(2:3)]
n <- nrow(xm)
f1 <- data.matrix(xm[, -1])
y <- xm[, 1]
f2 <- array(f1, c(n, ncol(x), l))
f3 <- f2[,, l:1]
f4 <- aperm(f3, c(1, 3, 2))
list(f4, y)
}
trnt <- tensorin(7, sdtf)
X <- trnt[1]
y <- trnt[2]
X[[1]][1,,]
y[[1]][1]
library(keras)
model <- keras_model_sequential() %>%
layer_simple_rnn(units = 24,
input_shape = list(7, 6),
dropout = 0.1, recurrent_dropout = 0.1) %>%
layer_dense(units = 1)
model %>% compile(optimizer = optimizer_rmsprop(),
loss = "mse")
dim(X[[1]])
train <- 1:208
test <- 208:dim(X[[1]])[1]
rnn <- model %>% fit(
X[[1]][train,, ], y[[1]][train], batch_size = 12, epochs = 75,
validation_data =
list(X[[1]][test,, ], y[[1]][test]),
verbose = 0
)
rnn %>% plot()
rnn
model()
model
save_model_hdf5(model$fit, "keras_fit.hdf5")
model$fit
model
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- rnn %>% predict(X[[1]][test,, ])
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- model %>% predict(X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
save_model_hdf5(model$fit, "model.hdf5")
model %>% evaluate(X[[1]][test,, ],  y[[1]][test], verbose = 2)
y_act <- y[[1]][test]
var_y <- var(y_act)
yhat <- model %>% predict(X[[1]][test,, ])
1 - mean((yhat -y_act)^2) / var_y # R^2
sqrt(mean((yhat -y_act)^2)) # RMSPE
knitr::include_graphics("png/LSTM3.png")
